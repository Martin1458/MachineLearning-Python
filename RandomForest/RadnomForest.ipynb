{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest of decision trees to specify a bird species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>attid</th>\n",
       "      <th>present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imgid  attid  present\n",
       "0      1      1        0\n",
       "1      1      2        0\n",
       "2      1      3        0\n",
       "3      1      4        0\n",
       "4      1      5        1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Some lines have too many undefined values, this will skip them\n",
    "imgatt = pd.read_csv(r\"C:\\Users\\marti\\Desktop\\PythonProjects\\MachineLearning-Python\\RandomForest\\CUB_200_2011\\attributes\\image_attribute_labels.txt\", sep='\\s+', header=None, usecols=[0,1,2], names=['imgid', 'attid', 'present'])\n",
    "\n",
    "imgatt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------- MTurk image attribute labels (attributes/image_attribute_labels.txt) ------\n",
    "The set of attribute labels as perceived by MTurkers for each image is contained in the file attributes/image_attribute_labels.txt, with each line corresponding to one image/attribute/worker triplet:\n",
    "\n",
    "<image_id> <attribute_id> <is_present> <certainty_id> <time>\n",
    "\n",
    "where <image_id>, <attribute_id>, <certainty_id> correspond to the IDs in images.txt, attributes/attributes.txt, and attributes/certainties.txt respectively.  <is_present> is 0 or 1 (1 denotes that the attribute is present).  <time> denotes the time spent by the MTurker in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3677856, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get number of rows and columns\n",
    "imgatt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganizing imgatt to have row per imgid, and 312 columns (one column per attribute), with 1/0 in each cell representing if that imgid has that attribute or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>attid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "attid  1    2    3    4    5    6    7    8    9    10   ...  303  304  305  \\\n",
       "imgid                                                    ...                  \n",
       "1        0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "5        0    0    0    0    1    0    0    0    0    0  ...    0    0    1   \n",
       "\n",
       "attid  306  307  308  309  310  311  312  \n",
       "imgid                                     \n",
       "1        0    0    1    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    1    0    0    1    0  \n",
       "4        1    0    0    1    0    0    0  \n",
       "5        0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgatt2 = imgatt.pivot(index='imgid', columns='attid', values='present')\n",
    "imgatt2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "imgid       \n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "5          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imglabels = pd.read_csv(r'C:\\Users\\marti\\Desktop\\PythonProjects\\MachineLearning-Python\\RandomForest\\CUB_200_2011\\image_class_labels.txt', sep=' ', header=None, names=['imgid', 'label'])\n",
    "imglabels = imglabels.set_index('imgid')\n",
    "imglabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------- Image class labels (image_class_labels.txt) ------\n",
    "The ground truth class labels (bird species labels) for each image are contained in the file image_class_labels.txt, with each line corresponding to one image:\n",
    "\n",
    "<image_id> <class_id>\n",
    "\n",
    "where <image_id> and <class_id> correspond to the IDs in images.txt and classes.txt, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move the label column to the imgatt2 data frame, then we will shuffle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3  4  5  6  7  8  9  10  ...  304  305  306  307  308  309  310  \\\n",
       "imgid                                 ...                                      \n",
       "7606   0  0  0  0  0  0  0  1  0   0  ...    0    0    0    0    1    0    0   \n",
       "157    0  0  0  0  1  0  0  0  0   0  ...    0    0    0    0    1    1    0   \n",
       "9640   0  0  0  0  0  0  0  1  0   0  ...    0    0    0    0    1    0    0   \n",
       "11379  0  0  0  0  0  0  1  0  0   0  ...    0    0    0    0    0    0    0   \n",
       "5909   1  0  0  0  0  0  0  0  0   0  ...    0    0    1    0    0    0    0   \n",
       "\n",
       "       311  312  label  \n",
       "imgid                   \n",
       "7606     1    0    130  \n",
       "157      0    0      3  \n",
       "9640     1    0    164  \n",
       "11379    1    0    194  \n",
       "5909     0    1    101  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = imgatt2.join(imglabels)\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate labels from attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  303  304  305  \\\n",
       "imgid                                                    ...                  \n",
       "7606     0    0    0    0    0    0    0    1    0    0  ...    0    0    0   \n",
       "157      0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "9640     0    0    0    0    0    0    0    1    0    0  ...    0    0    0   \n",
       "11379    0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
       "5909     1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       306  307  308  309  310  311  312  \n",
       "imgid                                     \n",
       "7606     0    0    1    0    0    1    0  \n",
       "157      0    0    1    1    0    0    0  \n",
       "9640     0    0    1    0    0    1    0  \n",
       "11379    0    0    0    0    0    1    0  \n",
       "5909     1    0    0    0    0    0    1  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select first 312 rows\n",
    "df_att = df.iloc[:, :312]\n",
    "#Select everything after the first 312 rows\n",
    "df_label = df.iloc[:, 312:]\n",
    "\n",
    "df_att.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate test set from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_att = df_att[:8000]\n",
    "df_train_label = df_label[:8000]\n",
    "df_test_att = df_att[8000:]\n",
    "df_test_label = df_label[8000:]\n",
    "\n",
    "df_train_label = df_train_label['label']\n",
    "df_test_label = df_test_label['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Max features show the number of different columns each tree can look at.\n",
    "clf = RandomForestClassifier(max_features=50, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our data to the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=50, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_features=50, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_train_att, df_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use attributes from the first five rows of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130   3 164 194 101]\n",
      "The predicted values ware 46% correct\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(df_train_att.head()))\n",
    "\n",
    "print('The predicted values ware '+str(int(float(clf.score(df_test_att, df_test_label))*100))+r'% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  2,  3, ...,  0,  0,  0],\n",
       "       [ 0, 16,  0, ...,  0,  0,  0],\n",
       "       [ 1,  2, 10, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  1, ...,  1,  0,  0],\n",
       "       [ 0,  0,  0, ...,  1,  5,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 15]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred_labels = clf.predict(df_test_att)\n",
    "cm = confusion_matrix(df_test_label, pred_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function copied from sklearn documentation to plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "#The following function was proudly stolen from the Wayback archive: https://web.archive.org/web/20180807180209/http://scikit-learn.org:80/stable/auto_examples/model_selection/plot_confusion_matrix.html [Edited]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    #for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    #    plt.text(j, i, format(cm[i, j], fmt),\n",
    "    #             horizontalalignment=\"center\",\n",
    "    #             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the actual names of the birds list so that we know the species that are being confused for each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      001.Black_footed_Albatross\n",
       "1            002.Laysan_Albatross\n",
       "2             003.Sooty_Albatross\n",
       "3           004.Groove_billed_Ani\n",
       "4              005.Crested_Auklet\n",
       "                  ...            \n",
       "195                196.House_Wren\n",
       "196                197.Marsh_Wren\n",
       "197                 198.Rock_Wren\n",
       "198               199.Winter_Wren\n",
       "199       200.Common_Yellowthroat\n",
       "Name: birdname, Length: 200, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = pd.read_csv(r\"C:\\Users\\marti\\Desktop\\PythonProjects\\MachineLearning-Python\\RandomForest\\CUB_200_2011\\classes.txt\", sep='\\s+', header=None, usecols=[1], names=['birdname'])\n",
    "birds = birds['birdname']\n",
    "birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "if not path.exists('possibleOutput.png'):\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=(60, 60), dpi=300)\n",
    "    plot_confusion_matrix(cm, classes=birds, normalize=True)\n",
    "    plt.savefig('possibleOutput.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare SVM model with Tree model with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values of tree model ware 27% correct\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clftree = tree.DecisionTreeClassifier()\n",
    "clftree.fit(df_train_att, df_train_label)\n",
    "print('The predicted values of tree model ware '+str(int(float(clftree.score(df_test_att, df_test_label))*100))+r'% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values of SVM model ware 49% correct\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clfsvm = svm.SVC()\n",
    "clfsvm.fit(df_train_att, df_train_label)\n",
    "print('The predicted values of SVM model ware '+str(int(float(clfsvm.score(df_test_att, df_test_label))*100))+r'% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values of Random Forest model ware 46% correct\n"
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(max_features=50, random_state=0, n_estimators=100)\n",
    "clf2.fit(df_train_att, df_train_label)\n",
    "print('The predicted values of Random Forest model ware '+str(int(float(clf2.score(df_test_att, df_test_label))*100))+r'% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform cross-validation to make sure that we split the training test in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marti\\Desktop\\PythonProjects\\MachineLearning-Python\\RandomForest\\RadnomForest.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/Desktop/PythonProjects/MachineLearning-Python/RandomForest/RadnomForest.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marti/Desktop/PythonProjects/MachineLearning-Python/RandomForest/RadnomForest.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(clf, df_train_att, df_train_label, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marti/Desktop/PythonProjects/MachineLearning-Python/RandomForest/RadnomForest.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy of Random Forest: \u001b[39m\u001b[39m%0.2f\u001b[39;00m\u001b[39m (+/- \u001b[39m\u001b[39m%0.2f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (scores\u001b[39m.\u001b[39mmean(), scores\u001b[39m.\u001b[39mstd() \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\tree\\_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    970\u001b[0m         X,\n\u001b[0;32m    971\u001b[0m         y,\n\u001b[0;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\MaybeVirus\\Python3.10.0\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, df_train_att, df_train_label, cv=5)\n",
    "print(\"Accuracy of Random Forest: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Tree: 0.25 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scorestree = cross_val_score(clftree, df_train_att, df_train_label, cv=5)\n",
    "print(\"Accuracy of Tree: %0.2f (+/- %0.2f)\" % (scorestree.mean(), scorestree.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM: 0.47 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scoressvm = cross_val_score(clfsvm, df_train_att, df_train_label, cv=5)\n",
    "print(\"Accuracy of SVM: %0.2f (+/- %0.2f)\" % (scoressvm.mean(), scoressvm.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through many different parameters in Random Forest and print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_features_opts = range(5, 100, 5)\n",
    "n_estimators_opts = range(10, 300, 20)\n",
    "rf_params = np.empty((len(max_features_opts) * len(n_estimators_opts), 4), float)\n",
    "i = 0\n",
    "for max_features in max_features_opts:\n",
    "    for n_estimators in n_estimators_opts:\n",
    "        clf = RandomForestClassifier(max_features=max_features, n_estimators=n_estimators)\n",
    "        scores = cross_val_score(clf, df_train_att, df_train_label, cv=5)\n",
    "        rf_params[i, 0] = max_features\n",
    "        rf_params[i, 1] = n_estimators\n",
    "        rf_params[i, 2] = scores.mean()\n",
    "        rf_params[i, 3] = scores.std() * 2\n",
    "        i += 1\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features, n_estimators, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_opts = range(5, 100, 5)\n",
    "n_estimators_opts = range(10, 300, 20)\n",
    "rf_params = np.empty((len(max_features_opts) * len(n_estimators_opts), 2), float)\n",
    "i = 0\n",
    "for max_features in max_features_opts:\n",
    "    for n_estimators in n_estimators_opts:\n",
    "        rf_params[i, 0] = max_features\n",
    "        rf_params[i, 1] = n_estimators\n",
    "        i += 1\n",
    "rf_params = rf_params.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_params[20].append(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for someList in rf_params:\n",
    "    if len(someList) <= 2:\n",
    "        pass\n",
    "    else:\n",
    "        print(someList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params_lists = []\n",
    "\n",
    "for o in range(len(max_features_opts)):\n",
    "    #print('rf_params['+str((o*15))+':'+str((o+1)*15)+']')\n",
    "    rf_params_lists.append(rf_params[o*15:(o+1)*15])\n",
    "#rf_params_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fIt():\n",
    "    for rows in range(len(rf_params_lists)):\n",
    "        for row in rf_params_lists[rows]:\n",
    "            row.append(rows)\n",
    "\n",
    "fIt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get1(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features1=int(row[0])\n",
    "        n_estimators1=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf1 = RandomForestClassifier(max_features=max_features1, n_estimators=n_estimators1)\n",
    "        scores1 = cross_val_score(clf1, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features1)\n",
    "        row.append(n_estimators1)\n",
    "        row.append(scores1.mean())\n",
    "        row.append(scores1.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features1, n_estimators1, scores1.mean(), scores1.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get2(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features2=int(row[0])\n",
    "        n_estimators2=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf2 = RandomForestClassifier(max_features=max_features2, n_estimators=n_estimators2)\n",
    "        scores2 = cross_val_score(clf2, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features2)\n",
    "        row.append(n_estimators2)\n",
    "        row.append(scores2.mean())\n",
    "        row.append(scores2.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features2, n_estimators2, scores2.mean(), scores2.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get3(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features3=int(row[0])\n",
    "        n_estimators3=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf3 = RandomForestClassifier(max_features=max_features3, n_estimators=n_estimators3)\n",
    "        scores3 = cross_val_score(clf3, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features3)\n",
    "        row.append(n_estimators3)\n",
    "        row.append(scores3.mean())\n",
    "        row.append(scores3.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features3, n_estimators3, scores3.mean(), scores3.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get4(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features4=int(row[0])\n",
    "        n_estimators4=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf4 = RandomForestClassifier(max_features=max_features4, n_estimators=n_estimators4)\n",
    "        scores4 = cross_val_score(clf4, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features4)\n",
    "        row.append(n_estimators4)\n",
    "        row.append(scores4.mean())\n",
    "        row.append(scores4.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features4, n_estimators4, scores4.mean(), scores4.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get5(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features5=int(row[0])\n",
    "        n_estimators5=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf5 = RandomForestClassifier(max_features=max_features5, n_estimators=n_estimators5)\n",
    "        scores5 = cross_val_score(clf5, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features5)\n",
    "        row.append(n_estimators5)\n",
    "        row.append(scores5.mean())\n",
    "        row.append(scores5.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features5, n_estimators5, scores5.mean(), scores5.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get6(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features6=int(row[0])\n",
    "        n_estimators6=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf6 = RandomForestClassifier(max_features=max_features6, n_estimators=n_estimators6)\n",
    "        scores6 = cross_val_score(clf6, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features6)\n",
    "        row.append(n_estimators6)\n",
    "        row.append(scores6.mean())\n",
    "        row.append(scores6.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features6, n_estimators6, scores6.mean(), scores6.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get7(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features7=int(row[0])\n",
    "        n_estimators7=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf7 = RandomForestClassifier(max_features=max_features7, n_estimators=n_estimators7)\n",
    "        scores7 = cross_val_score(clf7, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features7)\n",
    "        row.append(n_estimators7)\n",
    "        row.append(scores7.mean())\n",
    "        row.append(scores7.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features7, n_estimators7, scores7.mean(), scores7.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get8(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features8=int(row[0])\n",
    "        n_estimators8=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf8 = RandomForestClassifier(max_features=max_features8, n_estimators=n_estimators8)\n",
    "        scores8 = cross_val_score(clf8, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features8)\n",
    "        row.append(n_estimators8)\n",
    "        row.append(scores8.mean())\n",
    "        row.append(scores8.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features8, n_estimators8, scores8.mean(), scores8.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get9(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features9=int(row[0])\n",
    "        n_estimators9=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf9 = RandomForestClassifier(max_features=max_features9, n_estimators=n_estimators9)\n",
    "        scores9 = cross_val_score(clf9, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features9)\n",
    "        row.append(n_estimators9)\n",
    "        row.append(scores9.mean())\n",
    "        row.append(scores9.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features9, n_estimators9, scores9.mean(), scores9.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get10(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features10=int(row[0])\n",
    "        n_estimators10=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf10 = RandomForestClassifier(max_features=max_features10, n_estimators=n_estimators10)\n",
    "        scores10 = cross_val_score(clf10, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features10)\n",
    "        row.append(n_estimators10)\n",
    "        row.append(scores10.mean())\n",
    "        row.append(scores10.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features10, n_estimators10, scores10.mean(), scores10.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get11(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features11=int(row[0])\n",
    "        n_estimators11=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf11 = RandomForestClassifier(max_features=max_features11, n_estimators=n_estimators11)\n",
    "        scores11 = cross_val_score(clf11, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features11)\n",
    "        row.append(n_estimators11)\n",
    "        row.append(scores11.mean())\n",
    "        row.append(scores11.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features11, n_estimators11, scores11.mean(), scores11.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get12(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features12=int(row[0])\n",
    "        n_estimators12=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf12 = RandomForestClassifier(max_features=max_features12, n_estimators=n_estimators12)\n",
    "        scores12 = cross_val_score(clf12, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features12)\n",
    "        row.append(n_estimators12)\n",
    "        row.append(scores12.mean())\n",
    "        row.append(scores12.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features12, n_estimators12, scores12.mean(), scores12.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get13(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features13=int(row[0])\n",
    "        n_estimators13=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf13 = RandomForestClassifier(max_features=max_features13, n_estimators=n_estimators13)\n",
    "        scores13 = cross_val_score(clf13, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features13)\n",
    "        row.append(n_estimators13)\n",
    "        row.append(scores13.mean())\n",
    "        row.append(scores13.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features13, n_estimators13, scores13.mean(), scores13.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get14(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features14=int(row[0])\n",
    "        n_estimators14=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf14 = RandomForestClassifier(max_features=max_features14, n_estimators=n_estimators14)\n",
    "        scores14 = cross_val_score(clf14, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features14)\n",
    "        row.append(n_estimators14)\n",
    "        row.append(scores14.mean())\n",
    "        row.append(scores14.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features14, n_estimators14, scores14.mean(), scores14.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get15(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features15=int(row[0])\n",
    "        n_estimators15=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf15 = RandomForestClassifier(max_features=max_features15, n_estimators=n_estimators15)\n",
    "        scores15 = cross_val_score(clf15, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features15)\n",
    "        row.append(n_estimators15)\n",
    "        row.append(scores15.mean())\n",
    "        row.append(scores15.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features15, n_estimators15, scores15.mean(), scores15.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get16(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features16=int(row[0])\n",
    "        n_estimators16=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf16 = RandomForestClassifier(max_features=max_features16, n_estimators=n_estimators16)\n",
    "        scores16 = cross_val_score(clf16, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features16)\n",
    "        row.append(n_estimators16)\n",
    "        row.append(scores16.mean())\n",
    "        row.append(scores16.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features16, n_estimators16, scores16.mean(), scores16.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get17(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features17=int(row[0])\n",
    "        n_estimators17=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf17 = RandomForestClassifier(max_features=max_features17, n_estimators=n_estimators17)\n",
    "        scores17 = cross_val_score(clf17, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features17)\n",
    "        row.append(n_estimators17)\n",
    "        row.append(scores17.mean())\n",
    "        row.append(scores17.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features17, n_estimators17, scores17.mean(), scores17.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get18(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features18=int(row[0])\n",
    "        n_estimators18=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf18 = RandomForestClassifier(max_features=max_features18, n_estimators=n_estimators18)\n",
    "        scores18 = cross_val_score(clf18, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features18)\n",
    "        row.append(n_estimators18)\n",
    "        row.append(scores18.mean())\n",
    "        row.append(scores18.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features18, n_estimators18, scores18.mean(), scores18.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "def get19(rfrf):\n",
    "    global numberOfTestsDone\n",
    "    for row in rfrf:\n",
    "        max_features19=int(row[0])\n",
    "        n_estimators19=int(row[1])\n",
    "        print(\"Working on: max_featires={}, n_estimators={}\".format(row[0], row[1]))\n",
    "        clf19 = RandomForestClassifier(max_features=max_features19, n_estimators=n_estimators19)\n",
    "        scores19 = cross_val_score(clf19, df_train_att, df_train_label, cv=5)\n",
    "        row.append(max_features19)\n",
    "        row.append(n_estimators19)\n",
    "        row.append(scores19.mean())\n",
    "        row.append(scores19.std() * 2)\n",
    "        print(\"Max features: %d, num estimators: %d, accuracy: %0.2f (+/- %0.2f)\" % (max_features19, n_estimators19, scores19.mean(), scores19.std() * 2))\n",
    "        numberOfTestsDone += 1\n",
    "        print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "        print(\"%\")\n",
    "\n",
    "#get1(rf_params_lists[0])\n",
    "\n",
    "listOfThreadingFunctions = [get1, get2, get3, get4, get5, get6, get7, get8, get9, get10, get11, get12, get13, get14, get15, get16, get17, get18, get19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import threading\n",
    "\n",
    "def T1(xxx):\n",
    "    for i in range(0, 10):\n",
    "        sleep(0.1)\n",
    "        #print(xxx)\n",
    "        xxx += 1\n",
    "\n",
    "def T2(xxx):\n",
    "    for i in range(0, 10):\n",
    "        sleep(0.1)\n",
    "        #print(xxx)\n",
    "        xxx += 1\n",
    "thr1 = threading.Thread(target=T1, args=(0, ))\n",
    "thr2 = threading.Thread(target=T2, args=(0, ))\n",
    "thr1.start()\n",
    "sleep(0.12)\n",
    "thr2.start()\n",
    "#sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def T3(xx):\n",
    "    sleep(2)\n",
    "    print(xx)\n",
    "\n",
    "for i in range(5):\n",
    "    tttt = threading.Thread(target=T3, args=(2, ))\n",
    "    tttt.start()\n",
    "    \n",
    "tttt.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the whole threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "285\n",
      "100.70%\n"
     ]
    }
   ],
   "source": [
    "print(len(rf_params))\n",
    "print(19*15)\n",
    "\n",
    "numberOfTestsDone = 286\n",
    "numberOfTests = len(rf_params)\n",
    "numberOfTestsDone += 1\n",
    "print(\"%0.2f\" % ((numberOfTestsDone/numberOfTests)*100), end='')\n",
    "print(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "0.0%\n",
      "Working on: max_featires=5.0, n_estimators=10.0\n",
      "Working on: max_featires=10.0, n_estimators=10.0\n",
      "Working on: max_featires=15.0, n_estimators=10.0\n",
      "Working on: max_featires=20.0, n_estimators=10.0\n",
      "Working on: max_featires=25.0, n_estimators=10.0\n",
      "Working on: max_featires=30.0, n_estimators=10.0\n",
      "Working on: max_featires=35.0, n_estimators=10.0\n",
      "Working on: max_featires=40.0, n_estimators=10.0\n",
      "Working on: max_featires=45.0, n_estimators=10.0\n",
      "Working on: max_featires=50.0, n_estimators=10.0\n",
      "Working on: max_featires=55.0, n_estimators=10.0\n",
      "Working on: max_featires=60.0, n_estimators=10.0\n",
      "Working on: max_featires=65.0, n_estimators=10.0\n",
      "Working on: max_featires=70.0, n_estimators=10.0\n",
      "Working on: max_featires=75.0, n_estimators=10.0\n",
      "Working on: max_featires=80.0, n_estimators=10.0\n",
      "Working on: max_featires=85.0, n_estimators=10.0\n",
      "Working on: max_featires=90.0, n_estimators=10.0\n",
      "Working on: max_featires=95.0, n_estimators=10.0\n",
      "Max features: 5, num estimators: 10, accuracy: 0.25 (+/- 0.02)\n",
      "0.35%\n",
      "Working on: max_featires=5.0, n_estimators=30.0\n",
      "Max features: 10, num estimators: 10, accuracy: 0.28 (+/- 0.01)\n",
      "0.70%\n",
      "Working on: max_featires=10.0, n_estimators=30.0\n",
      "Max features: 15, num estimators: 10, accuracy: 0.31 (+/- 0.01)\n",
      "1.05%\n",
      "Working on: max_featires=15.0, n_estimators=30.0\n",
      "Max features: 20, num estimators: 10, accuracy: 0.31 (+/- 0.01)\n",
      "1.40%\n",
      "Working on: max_featires=20.0, n_estimators=30.0\n",
      "Max features: 25, num estimators: 10, accuracy: 0.31 (+/- 0.01)\n",
      "1.75%\n",
      "Working on: max_featires=25.0, n_estimators=30.0\n",
      "Max features: 30, num estimators: 10, accuracy: 0.32 (+/- 0.02)\n",
      "2.11%\n",
      "Working on: max_featires=30.0, n_estimators=30.0\n",
      "Max features: 35, num estimators: 10, accuracy: 0.32 (+/- 0.01)\n",
      "2.46%\n",
      "Working on: max_featires=35.0, n_estimators=30.0\n",
      "Max features: 40, num estimators: 10, accuracy: 0.33 (+/- 0.02)\n",
      "2.81%\n",
      "Working on: max_featires=40.0, n_estimators=30.0\n",
      "Max features: 45, num estimators: 10, accuracy: 0.33 (+/- 0.02)\n",
      "3.16%\n",
      "Working on: max_featires=45.0, n_estimators=30.0\n",
      "Max features: 55, num estimators: 10, accuracy: 0.33 (+/- 0.02)Max features: 50, num estimators: 10, accuracy: 0.34 (+/- 0.02)\n",
      "3.51%\n",
      "Working on: max_featires=50.0, n_estimators=30.0\n",
      "\n",
      "3.86%\n",
      "Working on: max_featires=55.0, n_estimators=30.0\n",
      "Max features: 60, num estimators: 10, accuracy: 0.33 (+/- 0.01)\n",
      "4.21%\n",
      "Working on: max_featires=60.0, n_estimators=30.0\n",
      "Max features: 65, num estimators: 10, accuracy: 0.34 (+/- 0.02)\n",
      "4.56%\n",
      "Working on: max_featires=65.0, n_estimators=30.0\n",
      "Max features: 70, num estimators: 10, accuracy: 0.34 (+/- 0.01)\n",
      "4.91%\n",
      "Working on: max_featires=70.0, n_estimators=30.0\n",
      "Max features: 75, num estimators: 10, accuracy: 0.34 (+/- 0.01)\n",
      "5.26%\n",
      "Working on: max_featires=75.0, n_estimators=30.0\n",
      "Max features: 80, num estimators: 10, accuracy: 0.34 (+/- 0.02)\n",
      "5.61%\n",
      "Working on: max_featires=80.0, n_estimators=30.0\n",
      "Max features: 85, num estimators: 10, accuracy: 0.34 (+/- 0.01)\n",
      "5.96%\n",
      "Working on: max_featires=85.0, n_estimators=30.0\n",
      "Max features: 90, num estimators: 10, accuracy: 0.34 (+/- 0.01)\n",
      "6.32%\n",
      "Working on: max_featires=90.0, n_estimators=30.0\n",
      "Max features: 95, num estimators: 10, accuracy: 0.34 (+/- 0.01)\n",
      "6.67%\n",
      "Working on: max_featires=95.0, n_estimators=30.0\n",
      "Max features: 5, num estimators: 30, accuracy: 0.34 (+/- 0.01)\n",
      "7.02%\n",
      "Working on: max_featires=5.0, n_estimators=50.0\n",
      "Max features: 10, num estimators: 30, accuracy: 0.37 (+/- 0.01)\n",
      "7.37%\n",
      "Working on: max_featires=10.0, n_estimators=50.0\n",
      "Max features: 15, num estimators: 30, accuracy: 0.39 (+/- 0.01)\n",
      "7.72%\n",
      "Working on: max_featires=15.0, n_estimators=50.0\n",
      "Max features: 20, num estimators: 30, accuracy: 0.39 (+/- 0.02)\n",
      "8.07%\n",
      "Working on: max_featires=20.0, n_estimators=50.0\n",
      "Max features: 25, num estimators: 30, accuracy: 0.39 (+/- 0.01)\n",
      "8.42%\n",
      "Working on: max_featires=25.0, n_estimators=50.0\n",
      "Max features: 30, num estimators: 30, accuracy: 0.39 (+/- 0.02)\n",
      "8.77%\n",
      "Working on: max_featires=30.0, n_estimators=50.0\n",
      "Max features: 35, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "9.12%\n",
      "Working on: max_featires=35.0, n_estimators=50.0\n",
      "Max features: 40, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "9.47%\n",
      "Working on: max_featires=40.0, n_estimators=50.0\n",
      "Max features: 5, num estimators: 50, accuracy: 0.38 (+/- 0.02)\n",
      "9.82%\n",
      "Working on: max_featires=5.0, n_estimators=70.0\n",
      "Max features: 45, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "10.18%\n",
      "Working on: max_featires=45.0, n_estimators=50.0\n",
      "Max features: 55, num estimators: 30, accuracy: 0.40 (+/- 0.02)\n",
      "10.53%\n",
      "Working on: max_featires=55.0, n_estimators=50.0\n",
      "Max features: 10, num estimators: 50, accuracy: 0.40 (+/- 0.01)\n",
      "10.88%\n",
      "Working on: max_featires=10.0, n_estimators=70.0\n",
      "Max features: 60, num estimators: 30, accuracy: 0.40 (+/- 0.03)\n",
      "11.23%\n",
      "Working on: max_featires=60.0, n_estimators=50.0\n",
      "Max features: 50, num estimators: 30, accuracy: 0.40 (+/- 0.02)\n",
      "11.58%\n",
      "Working on: max_featires=50.0, n_estimators=50.0\n",
      "Max features: 65, num estimators: 30, accuracy: 0.40 (+/- 0.02)\n",
      "11.93%\n",
      "Working on: max_featires=65.0, n_estimators=50.0\n",
      "Max features: 70, num estimators: 30, accuracy: 0.40 (+/- 0.02)\n",
      "12.28%\n",
      "Working on: max_featires=70.0, n_estimators=50.0\n",
      "Max features: 15, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "12.63%\n",
      "Working on: max_featires=15.0, n_estimators=70.0\n",
      "Max features: 75, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "12.98%\n",
      "Working on: max_featires=75.0, n_estimators=50.0\n",
      "Max features: 80, num estimators: 30, accuracy: 0.39 (+/- 0.01)\n",
      "13.33%\n",
      "Working on: max_featires=80.0, n_estimators=50.0\n",
      "Max features: 85, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "13.68%\n",
      "Working on: max_featires=85.0, n_estimators=50.0\n",
      "Max features: 90, num estimators: 30, accuracy: 0.39 (+/- 0.02)\n",
      "14.04%\n",
      "Working on: max_featires=90.0, n_estimators=50.0\n",
      "Max features: 20, num estimators: 50, accuracy: 0.42 (+/- 0.01)\n",
      "14.39%\n",
      "Working on: max_featires=20.0, n_estimators=70.0\n",
      "Max features: 25, num estimators: 50, accuracy: 0.41 (+/- 0.01)\n",
      "14.74%\n",
      "Working on: max_featires=25.0, n_estimators=70.0\n",
      "Max features: 95, num estimators: 30, accuracy: 0.40 (+/- 0.01)\n",
      "15.09%\n",
      "Working on: max_featires=95.0, n_estimators=50.0\n",
      "Max features: 5, num estimators: 70, accuracy: 0.40 (+/- 0.02)\n",
      "15.44%\n",
      "Working on: max_featires=5.0, n_estimators=90.0\n",
      "Max features: 30, num estimators: 50, accuracy: 0.42 (+/- 0.02)\n",
      "15.79%\n",
      "Working on: max_featires=30.0, n_estimators=70.0\n",
      "Max features: 35, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "16.14%\n",
      "Working on: max_featires=35.0, n_estimators=70.0\n",
      "Max features: 10, num estimators: 70, accuracy: 0.42 (+/- 0.01)\n",
      "16.49%\n",
      "Working on: max_featires=10.0, n_estimators=90.0\n",
      "Max features: 40, num estimators: 50, accuracy: 0.42 (+/- 0.02)\n",
      "16.84%\n",
      "Working on: max_featires=40.0, n_estimators=70.0\n",
      "Max features: 15, num estimators: 70, accuracy: 0.42 (+/- 0.02)\n",
      "17.19%\n",
      "Working on: max_featires=15.0, n_estimators=90.0\n",
      "Max features: 45, num estimators: 50, accuracy: 0.42 (+/- 0.02)\n",
      "17.54%\n",
      "Working on: max_featires=45.0, n_estimators=70.0\n",
      "Max features: 55, num estimators: 50, accuracy: 0.42 (+/- 0.01)\n",
      "17.89%\n",
      "Working on: max_featires=55.0, n_estimators=70.0\n",
      "Max features: 50, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "18.25%\n",
      "Working on: max_featires=50.0, n_estimators=70.0\n",
      "Max features: 5, num estimators: 90, accuracy: 0.42 (+/- 0.01)\n",
      "18.60%\n",
      "Working on: max_featires=5.0, n_estimators=110.0\n",
      "Max features: 60, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "18.95%\n",
      "Working on: max_featires=60.0, n_estimators=70.0\n",
      "Max features: 20, num estimators: 70, accuracy: 0.43 (+/- 0.02)\n",
      "19.30%\n",
      "Working on: max_featires=20.0, n_estimators=90.0\n",
      "Max features: 65, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "19.65%\n",
      "Working on: max_featires=65.0, n_estimators=70.0\n",
      "Max features: 25, num estimators: 70, accuracy: 0.43 (+/- 0.02)\n",
      "20.00%\n",
      "Working on: max_featires=25.0, n_estimators=90.0\n",
      "Max features: 70, num estimators: 50, accuracy: 0.41 (+/- 0.02)\n",
      "20.35%\n",
      "Working on: max_featires=70.0, n_estimators=70.0\n",
      "Max features: 75, num estimators: 50, accuracy: 0.42 (+/- 0.02)\n",
      "20.70%\n",
      "Working on: max_featires=75.0, n_estimators=70.0\n",
      "Max features: 10, num estimators: 90, accuracy: 0.43 (+/- 0.02)\n",
      "21.05%\n",
      "Working on: max_featires=10.0, n_estimators=110.0\n",
      "Max features: 30, num estimators: 70, accuracy: 0.42 (+/- 0.02)\n",
      "21.40%\n",
      "Working on: max_featires=30.0, n_estimators=90.0\n",
      "Max features: 80, num estimators: 50, accuracy: 0.42 (+/- 0.02)\n",
      "21.75%\n",
      "Working on: max_featires=80.0, n_estimators=70.0\n"
     ]
    }
   ],
   "source": [
    "#listOfThreadingFunctions is a list of functions\n",
    "#rf_params_lists is a list of chunks of parameters\n",
    "print(len(rf_params_lists))\n",
    "print(len(listOfThreadingFunctions))\n",
    "numberOfTestsDone = 0\n",
    "numberOfTests = len(rf_params)\n",
    "print(str((numberOfTestsDone/numberOfTests)*100)+\"%\")\n",
    "for i in range(len(rf_params_lists)):\n",
    "     lastThread = threading.Thread(target=listOfThreadingFunctions[i], args=(rf_params_lists[i], ))\n",
    "     lastThread.start()\n",
    "\n",
    "lastThread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test = rf_params_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 10.0, 0]\n",
      "[[5.0, 10.0, 0], [5.0, 30.0, 0], [5.0, 50.0, 0], [5.0, 70.0, 0], [5.0, 90.0, 0], [5.0, 110.0, 0], [5.0, 130.0, 0], [5.0, 150.0, 0], [5.0, 170.0, 0], [5.0, 190.0, 0], [5.0, 210.0, 0], [5.0, 230.0, 0], [5.0, 250.0, 0], [5.0, 270.0, 0], [5.0, 290.0, 0]]\n",
      "[5.0, 10.0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(rf_test[0][0])\n",
    "n_estimators_list = []\n",
    "max_features_list = []\n",
    "for Nrows in rf_test:\n",
    "    print(Nrows)\n",
    "    for oneRow in Nrows:\n",
    "        n_estimators_list.append(round(oneRow[0]))\n",
    "        n_estimators_list.append(round(oneRow[1]))\n",
    "        print(oneRow)\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eab74a2fd7fc163fedf2b539a8c720dd47c813b2947dad3f8a80b1139dc56d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
