{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import gensim to use Word2Vec and Doc2Vec, and logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-built Word2Vec model provided by Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 21:54:48,723 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "2023-02-26 21:55:10,905 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-02-26T21:55:10.905765', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "gmodel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the vector of the word cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gmodel['cat']\n",
    "len(gmodel[\"cat\"]) # 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the similarity between some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76094574"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.similarity(\"cat\", \"dog\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to format the data for the TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'<[^>]+>', ' ', sent) # strip html tags\n",
    "    sent = re.sub(r'(\\w)\\'(\\w)', '\\1\\2', sent) # remove apostrophes\n",
    "    sent = re.sub(r'\\W', ' ', sent) # remove punctuation\n",
    "    sent = re.sub(r'\\s+', ' ', sent) # remove repeated spaces\n",
    "    sent = sent.strip()\n",
    "    return sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised training data\n",
    "import re\n",
    "import os\n",
    "unsup_sentences = []\n",
    "\n",
    "# source: https://ai.stanford.edu/~amaas/data/sentiment, data from IMDB\n",
    "for dirname in ['train/pos', \"train/neg\", \"train/unsup\", \"test/pos\", \"test/neg\"]:\n",
    "    for fname in sorted(os.listdir(\"aclImdb/\"+dirname)):\n",
    "        if fname[-4:] == \".txt\":\n",
    "            with open(\"aclImdb/\"+dirname+\"/\"+fname, encoding=\"UTF-8\") as f:\n",
    "                sent = f.read()\n",
    "                words = extract_words(sent)\n",
    "                unsup_sentences.append(TaggedDocument(words, [dirname+\"/\"+fname]))\n",
    "\n",
    "# source: http://cs.cornell.edu/people/pabo/movie-review-data/\n",
    "for dirname in [\"txt_sentoken/pos\", \"txt_sentoken/neg\"]:\n",
    "    for fname in sorted(os.listdir(dirname)):\n",
    "        if fname[-4:] == \".txt\":\n",
    "            with open(dirname + \"/\" + fname, encoding=\"UTF-8\") as f:\n",
    "                for i, sent in enumerate(f):\n",
    "                    words = extract_words(sent)\n",
    "                    unsup_sentences.append(TaggedDocument(words, [\"%s/%s-%d\" % (dirname, fname, i)]))\n",
    "\n",
    "# source: https://nlp.stanford.edu/sentiment/, data from Rottn Tomatoes\n",
    "with open(\"stanfordSentimentTreebank/original_rt_snippets.txt\", encoding=\"UTF-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        words = extract_words(sent)\n",
    "        unsup_sentences.append(TaggedDocument(words, [\"rt-%d\" % i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', 'such', 'as', 'teachers', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', 'hig', 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', 'teachers', 'the', 'scramble', 'to', 'survive', 'financially', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', 'pomp', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', 'i', 'immediately', 'recalled', 'at', 'high', 'a', 'classic', 'line', 'inspector', 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', 'student', 'welcome', 'to', 'bromwell', 'high', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched', 'what', 'a', 'pity', 'that', 'it', 'is'], ['train/pos/0_9.txt']>\n"
     ]
    }
   ],
   "source": [
    "len(unsup_sentences)\n",
    "print(unsup_sentences[0]) # first sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a shuffeling class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class PermuteSentences(object):\n",
    "    def __init__(self, sents):\n",
    "        self.sents = sents\n",
    "    \n",
    "    def __iter__(self):\n",
    "        shuffeled = list(self.sents)\n",
    "        random.shuffle(shuffeled)\n",
    "        for sent in shuffeled:\n",
    "            yield sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets shuffle the sentences and fit them into our Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 22:21:39,715 : INFO : collecting all words and their counts\n",
      "2023-02-26 22:21:39,836 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-02-26 22:21:40,124 : INFO : PROGRESS: at example #10000, processed 1401401 words (4873031 words/s), 45400 word types, 10000 tags\n",
      "2023-02-26 22:21:40,392 : INFO : PROGRESS: at example #20000, processed 2839828 words (5397229 words/s), 61709 word types, 20000 tags\n",
      "2023-02-26 22:21:40,659 : INFO : PROGRESS: at example #30000, processed 4243392 words (5258399 words/s), 73168 word types, 30000 tags\n",
      "2023-02-26 22:21:40,925 : INFO : PROGRESS: at example #40000, processed 5642275 words (5282198 words/s), 82696 word types, 40000 tags\n",
      "2023-02-26 22:21:41,211 : INFO : PROGRESS: at example #50000, processed 7090241 words (5072916 words/s), 91075 word types, 50000 tags\n",
      "2023-02-26 22:21:41,487 : INFO : PROGRESS: at example #60000, processed 8519346 words (5202009 words/s), 98556 word types, 60000 tags\n",
      "2023-02-26 22:21:41,761 : INFO : PROGRESS: at example #70000, processed 9924053 words (5149349 words/s), 105157 word types, 70000 tags\n",
      "2023-02-26 22:21:42,028 : INFO : PROGRESS: at example #80000, processed 11308415 words (5186063 words/s), 110978 word types, 80000 tags\n",
      "2023-02-26 22:21:42,297 : INFO : PROGRESS: at example #90000, processed 12702041 words (5216505 words/s), 116520 word types, 90000 tags\n",
      "2023-02-26 22:21:42,562 : INFO : PROGRESS: at example #100000, processed 14116739 words (5364367 words/s), 122054 word types, 100000 tags\n",
      "2023-02-26 22:21:42,828 : INFO : PROGRESS: at example #110000, processed 15508648 words (5244657 words/s), 127220 word types, 110000 tags\n",
      "2023-02-26 22:21:43,103 : INFO : PROGRESS: at example #120000, processed 16921864 words (5143512 words/s), 132069 word types, 120000 tags\n",
      "2023-02-26 22:21:43,372 : INFO : PROGRESS: at example #130000, processed 18348454 words (5320730 words/s), 136678 word types, 130000 tags\n",
      "2023-02-26 22:21:43,635 : INFO : PROGRESS: at example #140000, processed 19740416 words (5308354 words/s), 141024 word types, 140000 tags\n",
      "2023-02-26 22:21:44,521 : INFO : PROGRESS: at example #150000, processed 21144642 words (1586837 words/s), 145148 word types, 150000 tags\n",
      "2023-02-26 22:21:44,786 : INFO : PROGRESS: at example #160000, processed 22528185 words (5243141 words/s), 149283 word types, 160000 tags\n",
      "2023-02-26 22:21:45,060 : INFO : PROGRESS: at example #170000, processed 23935382 words (5146668 words/s), 153316 word types, 170000 tags\n",
      "2023-02-26 22:21:46,051 : INFO : collected 155374 word types and 175325 unique tags from a corpus of 175325 examples and 24693510 words\n",
      "2023-02-26 22:21:46,052 : INFO : Creating a fresh vocabulary\n",
      "2023-02-26 22:21:46,288 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 57730 unique words (37.16% of original 155374, drops 97644)', 'datetime': '2023-02-26T22:21:46.288762', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-26 22:21:46,289 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 24537325 word corpus (99.37% of original 24693510, drops 156185)', 'datetime': '2023-02-26T22:21:46.289759', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-26 22:21:46,555 : INFO : deleting the raw counts dictionary of 155374 items\n",
      "2023-02-26 22:21:46,560 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-02-26 22:21:46,561 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 18578883.228339408 word corpus (75.7%% of prior 24537325)', 'datetime': '2023-02-26T22:21:46.561576', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2023-02-26 22:21:46,929 : INFO : estimated required memory for 57730 words and 50 dimensions: 122087000 bytes\n",
      "2023-02-26 22:21:46,930 : INFO : resetting layer weights\n",
      "2023-02-26 22:21:46,983 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 57730 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-26T22:21:46.983520', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2023-02-26 22:21:48,006 : INFO : EPOCH 0 - PROGRESS: at 6.70% examples, 1230909 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:49,008 : INFO : EPOCH 0 - PROGRESS: at 14.26% examples, 1321167 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:50,011 : INFO : EPOCH 0 - PROGRESS: at 21.70% examples, 1345249 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:51,019 : INFO : EPOCH 0 - PROGRESS: at 29.03% examples, 1349842 words/s, in_qsize 4, out_qsize 1\n",
      "2023-02-26 22:21:52,021 : INFO : EPOCH 0 - PROGRESS: at 36.17% examples, 1349484 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:53,023 : INFO : EPOCH 0 - PROGRESS: at 43.60% examples, 1354587 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:54,035 : INFO : EPOCH 0 - PROGRESS: at 51.13% examples, 1358425 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:55,042 : INFO : EPOCH 0 - PROGRESS: at 58.73% examples, 1365409 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:56,047 : INFO : EPOCH 0 - PROGRESS: at 66.14% examples, 1368838 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:57,053 : INFO : EPOCH 0 - PROGRESS: at 73.68% examples, 1372142 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:58,064 : INFO : EPOCH 0 - PROGRESS: at 81.27% examples, 1374920 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:21:59,068 : INFO : EPOCH 0 - PROGRESS: at 88.90% examples, 1378580 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:00,073 : INFO : EPOCH 0 - PROGRESS: at 96.36% examples, 1380846 words/s, in_qsize 4, out_qsize 1\n",
      "2023-02-26 22:22:00,556 : INFO : EPOCH 0: training on 24693510 raw words (18752227 effective words) took 13.6s, 1382809 effective words/s\n",
      "2023-02-26 22:22:01,566 : INFO : EPOCH 1 - PROGRESS: at 6.84% examples, 1285556 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:02,569 : INFO : EPOCH 1 - PROGRESS: at 14.19% examples, 1320184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:03,574 : INFO : EPOCH 1 - PROGRESS: at 21.20% examples, 1311315 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:04,581 : INFO : EPOCH 1 - PROGRESS: at 28.70% examples, 1327806 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:05,582 : INFO : EPOCH 1 - PROGRESS: at 36.03% examples, 1338673 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:06,588 : INFO : EPOCH 1 - PROGRESS: at 43.37% examples, 1349726 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:07,592 : INFO : EPOCH 1 - PROGRESS: at 50.99% examples, 1357730 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:08,593 : INFO : EPOCH 1 - PROGRESS: at 58.54% examples, 1364899 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:09,596 : INFO : EPOCH 1 - PROGRESS: at 66.01% examples, 1368496 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:10,599 : INFO : EPOCH 1 - PROGRESS: at 73.51% examples, 1372708 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:11,606 : INFO : EPOCH 1 - PROGRESS: at 81.00% examples, 1375080 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:12,606 : INFO : EPOCH 1 - PROGRESS: at 88.54% examples, 1377802 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:13,607 : INFO : EPOCH 1 - PROGRESS: at 95.84% examples, 1377008 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:14,186 : INFO : EPOCH 1: training on 24693510 raw words (18755420 effective words) took 13.6s, 1376898 effective words/s\n",
      "2023-02-26 22:22:15,194 : INFO : EPOCH 2 - PROGRESS: at 6.67% examples, 1266326 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:16,203 : INFO : EPOCH 2 - PROGRESS: at 13.99% examples, 1318127 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:17,206 : INFO : EPOCH 2 - PROGRESS: at 21.43% examples, 1336907 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:18,207 : INFO : EPOCH 2 - PROGRESS: at 28.72% examples, 1344601 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:19,212 : INFO : EPOCH 2 - PROGRESS: at 36.16% examples, 1350183 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:20,214 : INFO : EPOCH 2 - PROGRESS: at 43.65% examples, 1359556 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:21,218 : INFO : EPOCH 2 - PROGRESS: at 51.10% examples, 1362834 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:22,222 : INFO : EPOCH 2 - PROGRESS: at 58.60% examples, 1369195 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:23,222 : INFO : EPOCH 2 - PROGRESS: at 65.92% examples, 1369931 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:24,227 : INFO : EPOCH 2 - PROGRESS: at 73.43% examples, 1374300 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:25,230 : INFO : EPOCH 2 - PROGRESS: at 80.84% examples, 1374555 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:26,233 : INFO : EPOCH 2 - PROGRESS: at 88.33% examples, 1377256 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:27,235 : INFO : EPOCH 2 - PROGRESS: at 95.73% examples, 1377119 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:27,801 : INFO : EPOCH 2: training on 24693510 raw words (18751933 effective words) took 13.6s, 1378192 effective words/s\n",
      "2023-02-26 22:22:28,811 : INFO : EPOCH 3 - PROGRESS: at 6.83% examples, 1290879 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:29,816 : INFO : EPOCH 3 - PROGRESS: at 14.39% examples, 1344858 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:30,817 : INFO : EPOCH 3 - PROGRESS: at 22.08% examples, 1375109 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:31,818 : INFO : EPOCH 3 - PROGRESS: at 29.42% examples, 1377988 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:32,822 : INFO : EPOCH 3 - PROGRESS: at 37.04% examples, 1387786 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:33,823 : INFO : EPOCH 3 - PROGRESS: at 44.44% examples, 1390170 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:34,838 : INFO : EPOCH 3 - PROGRESS: at 52.12% examples, 1393563 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:35,840 : INFO : EPOCH 3 - PROGRESS: at 59.79% examples, 1398142 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:36,844 : INFO : EPOCH 3 - PROGRESS: at 67.35% examples, 1399348 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:37,852 : INFO : EPOCH 3 - PROGRESS: at 74.91% examples, 1398660 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:38,855 : INFO : EPOCH 3 - PROGRESS: at 82.16% examples, 1395146 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:39,856 : INFO : EPOCH 3 - PROGRESS: at 89.50% examples, 1393180 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:40,865 : INFO : EPOCH 3 - PROGRESS: at 96.88% examples, 1390652 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:41,287 : INFO : EPOCH 3: training on 24693510 raw words (18754645 effective words) took 13.5s, 1391706 effective words/s\n",
      "2023-02-26 22:22:42,299 : INFO : EPOCH 4 - PROGRESS: at 6.90% examples, 1288944 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:43,303 : INFO : EPOCH 4 - PROGRESS: at 14.32% examples, 1340393 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:44,309 : INFO : EPOCH 4 - PROGRESS: at 21.80% examples, 1363839 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:45,313 : INFO : EPOCH 4 - PROGRESS: at 29.31% examples, 1374826 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:46,314 : INFO : EPOCH 4 - PROGRESS: at 36.84% examples, 1381767 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:47,319 : INFO : EPOCH 4 - PROGRESS: at 44.14% examples, 1380190 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:48,327 : INFO : EPOCH 4 - PROGRESS: at 51.03% examples, 1364039 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:49,332 : INFO : EPOCH 4 - PROGRESS: at 58.52% examples, 1368815 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:50,335 : INFO : EPOCH 4 - PROGRESS: at 65.83% examples, 1370516 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:51,338 : INFO : EPOCH 4 - PROGRESS: at 73.41% examples, 1371851 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:52,340 : INFO : EPOCH 4 - PROGRESS: at 81.02% examples, 1375651 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:53,348 : INFO : EPOCH 4 - PROGRESS: at 88.68% examples, 1378786 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:54,354 : INFO : EPOCH 4 - PROGRESS: at 96.21% examples, 1381113 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:54,865 : INFO : EPOCH 4: training on 24693510 raw words (18754950 effective words) took 13.6s, 1382194 effective words/s\n",
      "2023-02-26 22:22:55,878 : INFO : EPOCH 5 - PROGRESS: at 6.94% examples, 1291163 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:56,882 : INFO : EPOCH 5 - PROGRESS: at 14.36% examples, 1348174 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:57,888 : INFO : EPOCH 5 - PROGRESS: at 21.85% examples, 1369409 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:58,889 : INFO : EPOCH 5 - PROGRESS: at 29.40% examples, 1376134 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:22:59,891 : INFO : EPOCH 5 - PROGRESS: at 36.87% examples, 1375334 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:00,891 : INFO : EPOCH 5 - PROGRESS: at 44.34% examples, 1375760 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:01,896 : INFO : EPOCH 5 - PROGRESS: at 51.59% examples, 1374744 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:02,896 : INFO : EPOCH 5 - PROGRESS: at 59.09% examples, 1377913 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:03,898 : INFO : EPOCH 5 - PROGRESS: at 66.75% examples, 1382685 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:04,899 : INFO : EPOCH 5 - PROGRESS: at 74.25% examples, 1384026 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:05,912 : INFO : EPOCH 5 - PROGRESS: at 81.76% examples, 1385493 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:06,915 : INFO : EPOCH 5 - PROGRESS: at 89.24% examples, 1387454 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:07,916 : INFO : EPOCH 5 - PROGRESS: at 96.81% examples, 1390837 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:08,350 : INFO : EPOCH 5: training on 24693510 raw words (18753131 effective words) took 13.5s, 1391670 effective words/s\n",
      "2023-02-26 22:23:09,358 : INFO : EPOCH 6 - PROGRESS: at 6.84% examples, 1269374 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:10,361 : INFO : EPOCH 6 - PROGRESS: at 14.26% examples, 1342811 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:11,372 : INFO : EPOCH 6 - PROGRESS: at 21.92% examples, 1368272 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:12,375 : INFO : EPOCH 6 - PROGRESS: at 29.59% examples, 1382075 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:13,385 : INFO : EPOCH 6 - PROGRESS: at 37.19% examples, 1389335 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:14,393 : INFO : EPOCH 6 - PROGRESS: at 44.86% examples, 1393319 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:15,400 : INFO : EPOCH 6 - PROGRESS: at 52.50% examples, 1397882 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:16,402 : INFO : EPOCH 6 - PROGRESS: at 60.24% examples, 1400836 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:17,408 : INFO : EPOCH 6 - PROGRESS: at 67.90% examples, 1403892 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:18,412 : INFO : EPOCH 6 - PROGRESS: at 75.36% examples, 1403277 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:19,415 : INFO : EPOCH 6 - PROGRESS: at 83.06% examples, 1405124 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:20,418 : INFO : EPOCH 6 - PROGRESS: at 90.65% examples, 1407140 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:21,421 : INFO : EPOCH 6 - PROGRESS: at 98.15% examples, 1409182 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:21,671 : INFO : EPOCH 6: training on 24693510 raw words (18756435 effective words) took 13.3s, 1408969 effective words/s\n",
      "2023-02-26 22:23:22,686 : INFO : EPOCH 7 - PROGRESS: at 6.73% examples, 1266941 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:23,694 : INFO : EPOCH 7 - PROGRESS: at 14.28% examples, 1326211 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:24,697 : INFO : EPOCH 7 - PROGRESS: at 21.67% examples, 1346125 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:25,701 : INFO : EPOCH 7 - PROGRESS: at 29.10% examples, 1360212 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:26,704 : INFO : EPOCH 7 - PROGRESS: at 36.56% examples, 1366657 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:27,706 : INFO : EPOCH 7 - PROGRESS: at 43.83% examples, 1366275 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-26 22:23:28,710 : INFO : EPOCH 7 - PROGRESS: at 51.27% examples, 1368156 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:29,711 : INFO : EPOCH 7 - PROGRESS: at 58.70% examples, 1370627 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:30,711 : INFO : EPOCH 7 - PROGRESS: at 66.09% examples, 1374691 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:31,712 : INFO : EPOCH 7 - PROGRESS: at 73.65% examples, 1376749 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:32,714 : INFO : EPOCH 7 - PROGRESS: at 81.11% examples, 1378253 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:33,715 : INFO : EPOCH 7 - PROGRESS: at 88.60% examples, 1380365 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:34,723 : INFO : EPOCH 7 - PROGRESS: at 96.18% examples, 1381938 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:35,239 : INFO : EPOCH 7: training on 24693510 raw words (18755526 effective words) took 13.6s, 1383390 effective words/s\n",
      "2023-02-26 22:23:36,251 : INFO : EPOCH 8 - PROGRESS: at 6.88% examples, 1291702 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:37,252 : INFO : EPOCH 8 - PROGRESS: at 14.52% examples, 1354961 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:38,259 : INFO : EPOCH 8 - PROGRESS: at 22.04% examples, 1370325 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:39,270 : INFO : EPOCH 8 - PROGRESS: at 29.50% examples, 1376522 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:40,273 : INFO : EPOCH 8 - PROGRESS: at 37.20% examples, 1384567 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:41,273 : INFO : EPOCH 8 - PROGRESS: at 44.74% examples, 1391269 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:42,275 : INFO : EPOCH 8 - PROGRESS: at 51.91% examples, 1388796 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:43,276 : INFO : EPOCH 8 - PROGRESS: at 59.12% examples, 1388800 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:44,279 : INFO : EPOCH 8 - PROGRESS: at 66.37% examples, 1383425 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:45,285 : INFO : EPOCH 8 - PROGRESS: at 73.33% examples, 1374634 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:46,289 : INFO : EPOCH 8 - PROGRESS: at 80.86% examples, 1376124 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:47,292 : INFO : EPOCH 8 - PROGRESS: at 88.38% examples, 1377695 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:48,296 : INFO : EPOCH 8 - PROGRESS: at 95.72% examples, 1376590 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:48,871 : INFO : EPOCH 8: training on 24693510 raw words (18753312 effective words) took 13.6s, 1376585 effective words/s\n",
      "2023-02-26 22:23:49,878 : INFO : EPOCH 9 - PROGRESS: at 6.48% examples, 1223301 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:50,889 : INFO : EPOCH 9 - PROGRESS: at 13.53% examples, 1271417 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:51,892 : INFO : EPOCH 9 - PROGRESS: at 21.11% examples, 1316669 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:52,894 : INFO : EPOCH 9 - PROGRESS: at 28.62% examples, 1341661 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:53,895 : INFO : EPOCH 9 - PROGRESS: at 36.09% examples, 1351224 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:54,905 : INFO : EPOCH 9 - PROGRESS: at 43.37% examples, 1351459 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:55,906 : INFO : EPOCH 9 - PROGRESS: at 50.47% examples, 1348279 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:56,908 : INFO : EPOCH 9 - PROGRESS: at 58.01% examples, 1354440 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:57,911 : INFO : EPOCH 9 - PROGRESS: at 65.67% examples, 1362731 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:58,920 : INFO : EPOCH 9 - PROGRESS: at 73.13% examples, 1367219 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:23:59,923 : INFO : EPOCH 9 - PROGRESS: at 80.70% examples, 1372185 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:24:00,926 : INFO : EPOCH 9 - PROGRESS: at 88.34% examples, 1375796 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:24:01,928 : INFO : EPOCH 9 - PROGRESS: at 95.97% examples, 1379632 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-26 22:24:02,461 : INFO : EPOCH 9: training on 24693510 raw words (18754678 effective words) took 13.6s, 1380944 effective words/s\n",
      "2023-02-26 22:24:02,462 : INFO : Doc2Vec lifecycle event {'msg': 'training on 246935100 raw words (187542257 effective words) took 135.5s, 1384490 effective words/s', 'datetime': '2023-02-26T22:24:02.462399', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2023-02-26 22:24:02,463 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-02-26T22:24:02.463396', 'gensim': '4.3.0', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "permuter = PermuteSentences(unsup_sentences)\n",
    "model = Doc2Vec(permuter, dm=0, hs=0, vector_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training, we free up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'delete_temporary_training_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marti\\Desktop\\PythonProjects\\MachineLearning-Python\\CommentClassification\\CommentClassification.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marti/Desktop/PythonProjects/MachineLearning-Python/CommentClassification/CommentClassification.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mdelete_temporary_training_data(keep_doctags_vectors\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, keep_interface\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'delete_temporary_training_data'"
     ]
    }
   ],
   "source": [
    "model.delete_temporary_training_data(keep_interface=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eab74a2fd7fc163fedf2b539a8c720dd47c813b2947dad3f8a80b1139dc56d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
